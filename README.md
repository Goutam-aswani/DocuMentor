# ðŸ¤– AI Chatbot with RAG & Authentication

A full-stack AI chatbot with document-based Q&A (RAG), multi-model support, and user authentication.

## Features

- **Multi-Model Chat** â€” Switch between Groq (Llama, Qwen, Kimi) and OpenRouter models
- **RAG (Retrieval-Augmented Generation)** â€” Upload PDFs, DOCX, or TXT files and ask questions grounded in your documents
- **Web Search** â€” Optional real-time web search via Tavily API
- **Authentication** â€” JWT-based auth with email verification, password reset
- **Usage Tracking** â€” Per-user daily stats (messages, tokens, model usage)
- **Streaming Responses** â€” Real-time token-by-token response streaming

## Tech Stack

| Layer | Technology |
|-------|-----------|
| **Backend** | FastAPI, LangChain, SQLModel |
| **Frontend** | React (Vite), Tailwind CSS |
| **Database** | PostgreSQL (Supabase) |
| **Vector DB** | Qdrant Cloud |
| **LLMs** | Groq, OpenRouter |
| **Embeddings** | Google Generative AI (gemini-embedding-001) |
| **Search** | Tavily API |

## Project Structure

```
â”œâ”€â”€ main.py                  # FastAPI entry point
â”œâ”€â”€ config.py                # Environment settings
â”œâ”€â”€ database.py              # DB engine + session
â”œâ”€â”€ models.py                # SQLModel schemas
â”œâ”€â”€ auth.py                  # Login / token endpoint
â”œâ”€â”€ users.py                 # Registration, verification, profile
â”œâ”€â”€ chats.py                 # Chat sessions, messaging, streaming
â”œâ”€â”€ rag.py                   # Document upload routes
â”œâ”€â”€ chatbot_service.py       # LLM chains (standard + RAG)
â”œâ”€â”€ rag_service.py           # Qdrant vector store + retrieval
â”œâ”€â”€ web_search_service.py    # Tavily search integration
â”œâ”€â”€ usage_tracker.py         # Usage statistics
â”œâ”€â”€ dependencies.py          # Auth middleware
â”œâ”€â”€ security.py              # JWT + bcrypt
â”œâ”€â”€ email_service.py         # Email via SMTP
â”œâ”€â”€ middleware.py             # CORS config
â”œâ”€â”€ limiter.py               # Rate limiting
â”œâ”€â”€ Dockerfile               # Container config
â”œâ”€â”€ render.yaml              # Render.com deploy blueprint
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ .env.example             # Environment template
â””â”€â”€ chatbot-frontend/        # React frontend
    â”œâ”€â”€ src/
    â”œâ”€â”€ vercel.json           # Vercel SPA config
    â””â”€â”€ .env.example
```

## Setup

### Backend

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows

# Install dependencies
pip install -r requirements.txt

# Copy and fill in environment variables
cp .env.example .env

# Run the server
uvicorn main:app --reload
```

### Frontend

```bash
cd chatbot-frontend
npm install
cp .env.example .env  # Set VITE_API_BASE_URL
npm run dev
```

## Environment Variables

See `.env.example` for all required variables. Key ones:

- `DATABASE_URL` â€” Supabase PostgreSQL connection string
- `QDRANT_URL` / `QDRANT_API_KEY` â€” Qdrant Cloud credentials
- `GOOGLE_API_KEY` â€” For embeddings
- `GROK_API_KEY` â€” Groq API key
- `OPENROUTER_API_KEY` â€” OpenRouter API key

## Deployment

- **Backend** â†’ [Render.com](https://render.com) (Dockerfile)
- **Frontend** â†’ [Vercel](https://vercel.com) (auto-detected Vite)
- **Database** â†’ [Supabase](https://supabase.com) (free PostgreSQL)
- **Vector DB** â†’ [Qdrant Cloud](https://cloud.qdrant.io) (free tier)
